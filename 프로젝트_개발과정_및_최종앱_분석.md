# Vocabulary DB → IRT CAT 어휘 진단 앱: 전체 개발 과정 및 최종 분석

---

## 목차

- [Part I. 개발 과정 (시간순)](#part-i-개발-과정-시간순)
  - [Phase 0: 원시 데이터 수집 (2021~2025)](#phase-0-원시-데이터-수집-20212025)
  - [Phase 1: 소스 데이터 체계화 (2026-02-07)](#phase-1-소스-데이터-체계화-2026-02-07)
  - [Phase 2: 마스터 데이터베이스 구축 (2026-02-07~13)](#phase-2-마스터-데이터베이스-구축-2026-02-0713)
  - [Phase 3: LLM 기반 대규모 데이터 보강 (2026-02-13~17)](#phase-3-llm-기반-대규모-데이터-보강-2026-02-1317)
  - [Phase 4: 그래프 데이터베이스 구축 (2026-02-07)](#phase-4-그래프-데이터베이스-구축-2026-02-07)
  - [Phase 5: IRT CAT 엔진 핵심 구현 (2026-02-19)](#phase-5-irt-cat-엔진-핵심-구현-2026-02-19)
  - [Phase 6: 고급 기능 확장 (2026-02-20)](#phase-6-고급-기능-확장-2026-02-20)
  - [Phase 7: 프론트엔드 및 리포팅 (2026-02-20~21)](#phase-7-프론트엔드-및-리포팅-2026-02-2021)
  - [Phase 8: 어휘 매트릭스 (2026-02-21)](#phase-8-어휘-매트릭스-2026-02-21)
  - [Phase 9: 배포 (2026-02-21~22)](#phase-9-배포-2026-02-2122)
  - [Phase 10: 혼합 문항 유형 활성화 (2026-02-22)](#phase-10-혼합-문항-유형-활성화-2026-02-22)
- [Part II. 다른 앱/프로젝트와의 관계](#part-ii-다른-앱프로젝트와의-관계)
- [Part III. 최종 앱 상세 분석](#part-iii-최종-앱-상세-분석)
  - [1. 앱 구조](#1-앱-구조)
  - [2. 기능 목록](#2-기능-목록)
  - [3. 작동 원리](#3-작동-원리)
  - [4. 사용 방법](#4-사용-방법)
  - [5. 장점](#5-장점)
  - [6. 한계점](#6-한계점)
  - [7. 추가 개선 가능성](#7-추가-개선-가능성)

---

# Part I. 개발 과정 (시간순)

## Phase 0: 원시 데이터 수집 (2021~2025)

### 배경

이 프로젝트의 시작은 **수년간 수작업으로 축적된 영어 어휘 자료**에서 출발한다. 여러 기여자가 다양한 형태의 파일로 어휘 데이터를 모았다.

### 핵심 자료

| 파일 | 내용 | 시기 |
|------|------|------|
| `7차교육과정-2607개.hwp` | 한국 7차 교육과정 어휘 2,607개 | 레거시 |
| `초등교과어휘primvoca.hwp` | 초등 교육과정 어휘 | 레거시 |
| `중등교과어휘MIDVOCA.hwp` | 중등 교육과정 어휘 | 레거시 |
| `HIGHVOC2.HWP` | 고등학교 어휘 | 레거시 |
| `TOEFLVOC.HWP` | TOEFL 어휘 | 레거시 |
| `VOC36000.HWP` | 36,000단어 대규모 어휘 목록 | 레거시 |
| `9000 words for Patrick_20250729.xlsx` | 9,000단어 초안 | 2021 |
| `9000Rank-options-included_20211206.xlsx` | 빈도순 정렬 + 선택지 포함 | 2021-12 |
| `YSJ-vocablist-example sentences_20220304.doc` | 예문 추가 작업 | 2022-03 |
| `교과어휘wordList_김현채 매니저_20220324.xlsx` | 협업 편집본 | 2022-03 |
| `RobDictionary-작업용_20250219.csv` | Rob의 사전 참조 자료 (9.2MB) | 2025-02 |

### 특징

- 한글(HWP) 파일, Excel, Word, CSV 등 **다양한 형식**이 혼재
- 최소 3명 이상의 기여자 참여 (YSJ, 김현채, 동민님, Patrick, Rob)
- "9,000단어" 컨셉이 2021년부터 존재 — 이것이 전체 프로젝트의 핵심 규모

### 위치

```
06_Archive/
├── Legacy_HWP/          ← 원본 HWP 파일들
└── Old_Versions/        ← 중간 작업물 (CSV, XLSX, DOC)
```

---

## Phase 1: 소스 데이터 체계화 (2026-02-07)

### 작업 내용

Dropbox/Google Drive에 흩어져 있던 파일들을 **카테고리별 폴더 구조**로 재편성했다.

### 폴더 구조

```
01_Korea_Curriculum/         ← 한국 교육과정 기반 어휘
├── Elementary/              3-4학년, 5-6학년 교과 어휘
├── Middle_School/           중학교 공통 어휘
└── High_School/             고등학교 어휘 (Korea_Vocab_3500_Verified.xlsx)

02_Standardized_Tests/       ← 표준화 시험 어휘
├── CSAT/                    수능 어휘 (CSAT_Vocabulary.csv, 346KB)
├── TOEFL/                   TOEFL 어휘 (TOEFL_Vocabulary.csv, 235KB)
└── Academic/                학술 어휘 (AWL, 596KB)

03_International_Standards/  ← 국제 기준 어휘
├── CEFR/                    A1~C2 레벨별 CSV (+ CEFR-J Wordlist)
├── GSE_Pearson/             GSE 점수 데이터 (919KB)
└── Lexile/                  75개 이상의 Lexile 대역별 CSV
```

### 의의

이 체계화 작업으로 각 단어에 **다차원적 메타데이터**를 부여하는 기반이 마련되었다:
- CEFR 레벨, 한국 교육과정 학년, GSE 점수, Lexile 대역, 수능/TOEFL 포함 여부 등

---

## Phase 2: 마스터 데이터베이스 구축 (2026-02-07~13)

### 목표

체계화된 소스 데이터를 하나의 **통합 데이터베이스**로 결합

### 결과물

| 파일 | 규모 | 용도 |
|------|------|------|
| `9000word_full_db.csv` | 7.8MB, **58컬럼 × 9,183행** | 전체 마스터 DB (TSV) |
| `9000vocab_master_table.csv` | 742KB, 6컬럼 × 9,003행 | 경량 요약본 |
| `vocabularyguide.md` | 10KB | 교육과정-DB 매핑 문서 |

### 58개 컬럼 구조

| 카테고리 | 컬럼 예시 |
|----------|-----------|
| **식별** | `word_display`, `stem`, `freq_rank`, `freq_info` |
| **언어학** | `pos`, `pos_detail`, `ipa`, `morpheme`, `word_formation`, `etymology` |
| **국제 기준** | `cefr`, `oxford3000`, `gsl`, `gse`, `lexile`, `eiken_level` |
| **한국 교육과정** | `kr_curriculum`, `grade_range`, `textbook_included`, `us_grade` |
| **의미 관계** | `synonym`, `antonym`, `hypernym`, `hyponym`, `collocation`, `word_family` |
| **교수법** | `learning_objective`, `error_pattern`, `teaching_method`, `educational_value` |
| **활용** | `register`, `domain`, `topic`, `regional_variant`, `era` |
| **예문** | `sentence_1`, `sentence_2`, `sentence_3` (난이도별 3단계) |
| **품질 관리** | `quality_grade`, `validation_result`, `status` |

### 초기 상태

- 전체 9,183행 중 **2,106행만** 완전한 데이터를 가지고 있었음
- 이 2,106행은 Google Apps Script + LLM 파이프라인(시스템 v3.3)으로 생성된 것
- 나머지 ~7,000행은 기본 정보만 있는 "빈 껍데기" 상태

---

## Phase 3: LLM 기반 대규모 데이터 보강 (2026-02-13~17)

### 문제

9,183개 중 7,000개 이상의 단어가 불완전 → 58개 컬럼을 전부 채워야 함

### 해결: Gemini API 배치 파이프라인

`05_Working_Files/` 디렉토리에 Python 파이프라인을 구축:

```
실행 순서:
1. find_missing_words.py     → 빈 단어 7,000개 식별
2. batch_fill_fulldb.py      → Gemini API로 10개씩 배치 생성 (체크포인트 + 재시도)
3. merge_to_fulldb.py        → 생성 결과를 마스터 DB에 병합 (중복 제거)
4. retry_failed_words.py     → API 실패분 재처리
5. fill_cleaned_gaps.py      → 누락 컬럼 보충
6. fix_remaining_issues.py   → 엣지 케이스 수정
7. priority_improvements.py  → 고우선순위 항목 집중 개선
8. quality_check.py          → 자동화 품질 검증 (마크다운 리포트 생성)
```

### 품질 개선 추이

| 날짜 | 행 수 | 잘못된 POS | 잘못된 교육과정 | 고아 참조 |
|------|-------|-----------|--------------|----------|
| 2/13 | 2,106 | 1,844개 | 347개 | 39.5% |
| 2/14 | ~4,000 | 감소 | 감소 | 감소 |
| 2/15 | ~6,000 | 감소 | 감소 | 감소 |
| **2/17** | **9,183** | **0개** | **0개** | **0%** |

### 최종 데이터 품질

- CEFR 유효성: **100%**
- POS 유효성: **100%**
- 중복: **0건**
- 동의어 채움률: **84.4%**
- 반의어 채움률: **43.1%** (자연적으로 반의어가 없는 단어가 많음)

---

## Phase 4: 그래프 데이터베이스 구축 (2026-02-07)

### 목표

테이블(행-열) 형태의 데이터를 **네트워크(그래프)** 구조로 변환하여 단어 간 의미 관계를 모델링

### 기술 스택

| 항목 | 기술 |
|------|------|
| 런타임 | Node.js |
| 그래프 라이브러리 | `graphology` |
| 시각화 | `vis.js` (인터랙티브 웹) |
| 온톨로지 모델 | WordNet Synset + SKOS + OntoLex-Lemon |

### 그래프 규모

```
노드: 17,376개
├── Word:        5,124
├── Example:     6,318
├── Synset:      2,106
├── Collocation: 2,464
├── Topic:       1,110
├── Domain:        243
├── CEFRLevel:       6
└── Curriculum:      5

엣지: 25,852개
├── HAS_EXAMPLE:     최대
├── SYNONYM_OF:    2,327
├── HYPERNYM_OF:   2,196
├── ANTONYM_OF:    1,635
├── HYPONYM_OF:      383
└── 기타 관계형 엣지
```

### 주요 파일

| 파일 | 역할 |
|------|------|
| `build_graph.js` (14KB) | CSV → 그래프 변환 엔진 |
| `query_graph.js` (13KB) | 10가지 쿼리 메서드 (단어 조회, CEFR 필터, 최단 경로 등) |
| `visualize_graph.html` (24KB) | 인터랙티브 웹 시각화 |
| `vocabulary_graph.json` (48.5MB) | 전체 직렬화 그래프 |

### IRT 앱과의 연결

이 그래프는 최종 IRT CAT 앱의 **Strategy D 오답 생성**에 직접 활용된다:
- `graph_connector.py`가 `vocabulary_graph.json`을 로드
- 상위어(hypernym)를 공유하는 "형제 단어"를 찾아 그럴듯한 오답으로 제시
- 예: "dog"의 오답 → "cat", "rabbit" (같은 "animal" 하위)

### 배포

- Vercel에 정적 사이트로 배포: **https://vocab-graph-db.vercel.app**

---

## Phase 5: IRT CAT 엔진 핵심 구현 (2026-02-19)

### 커밋 내역

```
4c39293 feat: Implement IRT-based vocabulary test engine
a9af0ba feat: Add demo script and tests for IRT-based vocabulary diagnostic test
```

### 구현 내용

1. **IRT 2PL 수학 모델** (`models/irt_2pl.py`)
   - 확률 함수: `P(θ) = c + (1-c) / (1 + exp(-a(θ-b)))`
   - 피셔 정보량 함수: `I(θ) = a² × P × Q`
   - 로그 우도 함수
   - 벡터화 버전 (NumPy)

2. **능력 추정기** (`models/ability_estimator.py`)
   - EAP(Expected A Posteriori): 41점 가우스-에르미트 구적법, N(0,1) 사전분포
   - MLE(Maximum Likelihood): 뉴턴-랩슨 반복법
   - 프로필 기반 초기 θ 추정

3. **IRT 파라미터 초기화** (`item_bank/parameter_initializer.py`)
   - 난이도(b): CEFR(35%) + 빈도(25%) + GSE(20%) + 교육과정(10%) + Lexile(10%) → 프로빗 변환
   - 변별도(a): 교육적 가치, 품사, 동의어 수, Oxford 3000 등 복합 조정

4. **CAT 세션** (`cat/session.py`)
   - 문항 선택 → 응답 기록 → θ 재추정 → 종료 판단 루프

5. **문항 선택기** (`cat/item_selector.py`)
   - 최대 피셔 정보량 기반 + 콘텐츠 제약 (주제 균형, 외래어 제한, 노출 통제)
   - 상위 5개 중 랜덤 선택으로 시험 다양성 보장

6. **종료 규칙** (`cat/stopping_rules.py`)
   - 최소 15문항, 최대 40문항
   - SE < 0.30 도달 시 조기 종료
   - 최근 5회 θ 수렴 시 종료

---

## Phase 6: 고급 기능 확장 (2026-02-20)

### 커밋 내역

```
7f3f689 feat: Add loanword filtering and don't-know option
7d7618c feat: Add remaining Phase 3-4 files (frontend, graph connector, calibrator, exposure analysis)
1bb40e8 feat: Implement 5D vocabulary dimension analysis
79f3bb0 feat: Implement personalized learning recommendations
```

### 구현 내용

1. **외래어(Loanword) 처리**
   - 130개 이상의 투명 외래어 목록 (`TRANSPARENT_LOANWORDS`)
   - 시험당 최대 2개 제한, 변별도 50% 감소
   - Type 1/2 → Type 3/5로 자동 리디렉션

2. **"모름" 버튼**
   - 3PL 모드에서 추측 확률(c)을 0으로 재정의 → 더 정확한 θ 추정
   - `dont_know_flags` 배열로 EAP 계산에 반영

3. **베이지안 온라인 보정** (`item_bank/calibrator.py`)
   - 누적 응답 데이터로 b, a, c 파라미터 점진적 업데이트
   - b: 아무 때나, a: 20+ 응답 후, c: 500+ 응답 후

4. **노출 분석** (`reporting/exposure_analysis.py`)
   - 풀 활용률, 유효 풀 크기, 지니 계수, CEFR별 분석
   - 풀 확장 필요 영역 자동 식별

5. **5차원 어휘 프로필** (`reporting/dimension_analyzer.py`)
   - 의미(Semantic), 관계(Relational), 문맥(Contextual), 형태(Form), 화용(Pragmatic)
   - 문항 유형별 차원 매핑으로 사후 분석

6. **맞춤 학습 추천** (`reporting/recommendation_engine.py`)
   - 점수 < 70% → 학습 필요, < 40% → 고우선순위
   - 차원별 5가지 연습 유형 생성
   - 4주 학습 로드맵

---

## Phase 7: 프론트엔드 및 리포팅 (2026-02-20~21)

### 커밋 내역

```
0e1b189 feat: Add translations for Phase 7 features
952b3b9 feat: Add new features and metrics
```

### 구현 내용

1. **React 프론트엔드** (React 19 + TypeScript + Vite)
   - SurveyScreen → TestScreen → ResultsScreen 3단계 흐름
   - 한국어/영어 이중 언어 지원 (`i18n/translations.ts`)
   - 레이더 차트, 도넛 차트, 바 차트 등 시각화

2. **고급 리포팅** (`reporting/score_mapper.py`)
   - θ → CEFR 확률 분포 (정규 CDF 기반)
   - θ → 추정 어휘 크기 (전체 풀의 P 합산)
   - Oxford 3000 핵심 어휘 커버리지
   - 종단적(longitudinal) 성장 분석

3. **결과 화면 4탭 구성**
   - 종합(Overview): CEFR 히어로 카드 + 레이더 차트 + Oxford 커버리지
   - 분석(Analysis): 차원별 바 차트 + 주제별 강약점 + 측정 상세
   - 학습(Learning): 맞춤 학습 계획 + 4주 로드맵
   - 매트릭스(Matrix): 어휘 지식 그리드

---

## Phase 8: 어휘 매트릭스 (2026-02-21)

### 커밋 내역

```
534d253 feat: Add vocabulary matrix generation and related API endpoints
165290a feat: Implement vocabulary matrix component
```

### 구현 내용

- **5단계 지식 상태**: 미학습(P<0.3) → 인식(0.3~0.5) → 발전(0.5~0.7) → 익숙(0.7~0.9) → 완전습득(0.9+)
- CEFR별 100개 샘플 단어 × 현재 상태 vs. 목표 상태 시각화
- API: `GET /api/v1/learn/{session_id}/matrix`

---

## Phase 9: 배포 (2026-02-21~22)

### 커밋 내역

```
1468032 feat: Update API base URL for environment variable
6370504 feat: Add Docker and ignore files
e59295a feat: Add gcloud commands for deployment
```

### 배포 아키텍처

```
사용자 브라우저
      │
      ▼
┌──────────────────┐
│  Vercel (프론트)   │  vocab-cat-test.vercel.app
└────────┬─────────┘
         │ HTTPS API
         ▼
┌──────────────────┐
│ Cloud Run (백엔드) │  vocab-cat-api-440067489993.us-central1.run.app
│  Docker 컨테이너   │
└────────┬─────────┘
         │
    ┌────┴────┐
    │ SQLite  │  (인메모리 세션 + 영구 저장)
    └─────────┘
```

### 배포 과정

1. **프론트엔드 → Vercel**
   - `VITE_API_BASE` 환경변수로 백엔드 URL 주입
   - `npm run build` → Vercel 자동 배포

2. **백엔드 → Google Cloud Run**
   - `Dockerfile`: Python 3.13-slim + FastAPI + NumPy/SciPy + 9,000단어 CSV
   - `.dockerignore` / `.gcloudignore`로 불필요 파일 제외 (프론트엔드, 테스트, 대용량 파일)
   - `gcloud run deploy` → 컨테이너 빌드 → 자동 스케일링 서비스

---

## Phase 10: 혼합 문항 유형 활성화 (2026-02-22)

### 커밋 내역

```
8ebafda fix: Update default question type to 0
f972923 feat: Implement mixed question type selection
```

### 문제

프론트엔드에서 `question_type: 1`이 하드코딩되어 있어 **Type 1 (한국어 뜻 고르기)만** 출제되고 있었음. 백엔드에는 6가지 유형이 이미 완전 구현되어 있었으나 사용되지 않고 있었음.

### 해결

1. **동적 유형 선택** (`session_manager.py`)
   - `choose_question_type()`: 진행도 + 데이터 가용성 + 균형 분배 기반
   - 점진적 도입: 0~4번은 [1,2], 5~14번은 [1,2,3,5], 15번+ 전체
   - `adjust_item_difficulty()`: 유형별 b 파라미터 보정 적용

2. **프론트엔드 UI** (`SurveyScreen.tsx`)
   - 문항 유형 선택 버튼 7개 (혼합 추천 + 개별 6유형)
   - 기본값을 0(혼합)으로 변경

3. **IRT 모델 변경 없음** — 162개 기존 테스트 전체 통과

---

# Part II. 다른 앱/프로젝트와의 관계

이 저장소에는 **3개의 독립적이면서 연결된 프로젝트**가 존재한다:

```
vocabulary-db/
├── [프로젝트 A] 어휘 데이터 파이프라인  (01~06 폴더 + 스크립트)
├── [프로젝트 B] 어휘 그래프 DB          (07_Graph_DB_Project/)
└── [프로젝트 C] IRT CAT 어휘 진단 앱   (irt_cat_engine/)
```

### 데이터 흐름

```
[A] 어휘 데이터 파이프라인
│
│   레거시 HWP/Excel (2021~)
│   → 카테고리 정리 (01~03 폴더)
│   → 마스터 DB 구축 (04 폴더)
│   → Gemini API 배치 보강 (05 폴더)
│   → 9000word_full_db.csv (58컬럼 × 9,183행)
│
├──────────────────────────────────────┐
│                                      │
▼                                      ▼
[B] 어휘 그래프 DB                    [C] IRT CAT 앱
│                                      │
│  9000word_full_db.csv                │  9000word_full_db.csv
│  → graphology 그래프 구축             │  → IRT 파라미터 초기화
│  → vocabulary_graph.json (48.5MB)    │  → 문항 생성/선택/채점
│  → vis.js 인터랙티브 시각화           │  → 진단 리포트 생성
│                                      │
└──────────── graph_connector.py ──────┘
              (그래프를 오답 생성에 활용)
```

### 각 프로젝트의 최종 앱에 대한 기여

| 프로젝트 | 기여 내용 | 최종 앱에서의 역할 |
|----------|----------|------------------|
| **A: 데이터 파이프라인** | 58컬럼 × 9,183행 DB | 전체 문항 풀의 원천 데이터 |
| | CEFR/GSE/Lexile/교육과정 매핑 | IRT 난이도(b) 계산의 5가지 입력 |
| | 동의어/반의어/상위어/하위어 | 6가지 문항 유형의 정답/오답 소스 |
| | 예문 3단계 | Type 5 (문장 빈칸) 문항 소스 |
| | 연어(collocation) 데이터 | Type 6 (연어 판단) 문항 소스 |
| | 품사/빈도/교육적 가치 | 변별도(a) 계산 및 콘텐츠 균형 |
| **B: 그래프 DB** | vocabulary_graph.json | Strategy D 오답 생성 (의미적 형제 단어) |
| | 상위어-하위어 네트워크 | "그럴듯하지만 틀린" 오답 품질 향상 |
| | 동의어 체인 | 오답에서 동의어 오염 방지 검증 |

---

# Part III. 최종 앱 상세 분석

## 1. 앱 구조

### 시스템 아키텍처

```
┌─────────────────────────────────────────────────────────┐
│                    프론트엔드 (Vercel)                     │
│  React 19 + TypeScript + Vite                           │
│  ┌──────────┐  ┌──────────┐  ┌────────────────────────┐ │
│  │ Survey   │→ │  Test    │→ │ Results (4탭)          │ │
│  │ Screen   │  │  Screen  │  │ Overview│Analysis│     │ │
│  │          │  │          │  │ Learning│Matrix  │     │ │
│  └──────────┘  └──────────┘  └────────────────────────┘ │
└───────────────────────┬─────────────────────────────────┘
                        │ HTTPS REST API
┌───────────────────────┴─────────────────────────────────┐
│                    백엔드 (Cloud Run)                      │
│  FastAPI + Python 3.13                                  │
│                                                         │
│  ┌─── API Layer ──────────────────────────────────────┐ │
│  │ routes_test.py    (시험 시작/응답/결과/히스토리)       │ │
│  │ routes_admin.py   (보정/통계/노출분석/정리)           │ │
│  │ routes_learn.py   (학습계획/매트릭스)                 │ │
│  │ session_manager.py (세션 관리 + 문항 생성)            │ │
│  └────────────────────┬───────────────────────────────┘ │
│                       │                                 │
│  ┌─── CAT Engine ─────┴───────────────────────────────┐ │
│  │ session.py         (CAT 세션 오케스트레이터)          │ │
│  │ item_selector.py   (최대정보량 + 콘텐츠 제약)         │ │
│  │ stopping_rules.py  (SE/수렴/최대문항 종료)            │ │
│  └────────────────────┬───────────────────────────────┘ │
│                       │                                 │
│  ┌─── IRT Models ─────┴───────────────────────────────┐ │
│  │ irt_2pl.py         (확률/정보량/우도 함수)            │ │
│  │ ability_estimator.py (EAP/MLE/초기추정)              │ │
│  └────────────────────┬───────────────────────────────┘ │
│                       │                                 │
│  ┌─── Item Bank ──────┴───────────────────────────────┐ │
│  │ parameter_initializer.py (메타데이터→IRT 파라미터)    │ │
│  │ distractor_engine.py     (4전략 오답 생성)           │ │
│  │ calibrator.py            (베이지안 온라인 보정)       │ │
│  └────────────────────┬───────────────────────────────┘ │
│                       │                                 │
│  ┌─── Data Layer ─────┴───────────────────────────────┐ │
│  │ load_vocabulary.py  (9,183단어 CSV 로딩/정제)        │ │
│  │ graph_connector.py  (그래프 DB 연결)                 │ │
│  │ topic_mapper.py     (3,300주제→27카테고리)           │ │
│  │ database.py         (SQLite + SQLAlchemy)           │ │
│  └────────────────────────────────────────────────────┘ │
│                                                         │
│  ┌─── Reporting ──────────────────────────────────────┐ │
│  │ score_mapper.py           (θ→CEFR/어휘수/교육과정)   │ │
│  │ dimension_analyzer.py     (5차원 분석)               │ │
│  │ recommendation_engine.py  (학습 계획 생성)           │ │
│  │ matrix_generator.py       (어휘 매트릭스)            │ │
│  │ exposure_analysis.py      (풀 건강도 분석)           │ │
│  └────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────┘
```

### 파일 수 및 규모

| 구분 | 파일 수 | 주요 언어 |
|------|---------|----------|
| 백엔드 코어 | 19개 .py | Python |
| 프론트엔드 | 15개 .tsx/.ts | TypeScript |
| 테스트 | 8개 .py | Python (162 테스트 케이스) |
| 설정/배포 | 5개 | Dockerfile, vercel.json 등 |
| 데이터 | 2개 | CSV (7.8MB) + JSON (48.5MB) |

### 데이터베이스 스키마

```sql
User
├── id (UUID)
├── nickname
├── grade
├── self_assess
├── exam_experience
└── created_at

TestSession
├── id (UUID)
├── user_id (FK → User)
├── started_at / completed_at
├── initial_theta / final_theta / final_se
├── reliability
├── cefr_level / cefr_probabilities (JSON)
├── curriculum_level
├── vocab_size_estimate
├── total_items / total_correct / accuracy
├── termination_reason
├── topic_strengths (JSON) / topic_weaknesses (JSON)
└── dimension_scores (JSON)

Response
├── id (Auto PK)
├── session_id (FK → TestSession)
├── item_id / word / question_type
├── is_correct / is_dont_know
├── response_time_ms / sequence
├── theta_before / theta_after
├── se_before / se_after
└── difficulty_b / discrimination_a

ItemExposure
├── item_id (PK) / word
├── admin_count / correct_count
└── last_administered
```

---

## 2. 기능 목록

### 핵심 기능

| # | 기능 | 설명 |
|---|------|------|
| 1 | **적응형 문항 선택** | 피셔 정보량 최대화 기반, 학생 실력에 맞춘 실시간 난이도 조절 |
| 2 | **6가지 문항 유형** | 한국어 뜻, 영어 정의, 동의어, 반의어, 문장 빈칸, 연어 판단 |
| 3 | **혼합 모드** | 진행도에 따라 점진적으로 유형을 다양화 (워밍업 → 본평가) |
| 4 | **EAP 능력 추정** | 41점 가우스-에르미트 구적법으로 매 문항 후 θ 재추정 |
| 5 | **적응형 종료** | SE < 0.30 또는 θ 수렴 시 조기 종료 (15~40문항) |
| 6 | **CEFR 진단** | θ → A1~C1 확률 분포 매핑 |
| 7 | **어휘 크기 추정** | 9,183개 단어 각각의 P 합산으로 추정 어휘 수 계산 |
| 8 | **5차원 프로필** | 의미·관계·문맥·형태·화용 5차원 레이더 차트 |
| 9 | **맞춤 학습 계획** | 약점 기반 4주 학습 로드맵 + 차원별 연습 |
| 10 | **어휘 매트릭스** | CEFR별 100단어 × 5단계 지식 상태 시각화 |

### 부가 기능

| # | 기능 | 설명 |
|---|------|------|
| 11 | **외래어 자동 처리** | 투명 외래어 130개+ 자동 감지, 유형 리디렉션, 노출 제한 |
| 12 | **"모름" 옵션** | 추측 노이즈 제거로 더 정확한 측정 |
| 13 | **한/영 전환** | 전체 UI 이중 언어 지원 |
| 14 | **테스트 히스토리** | 사용자별 과거 시험 결과 조회 |
| 15 | **종단적 분석** | 복수 세션 간 θ 변화 추적 (향상/유지/하락) |
| 16 | **Oxford 3000 커버리지** | 핵심 어휘 커버리지 도넛 차트 |
| 17 | **주제별 강약점** | 27개 주제 카테고리별 정답률 분석 |
| 18 | **노출 통제** | Sympson-Hetter 확률적 노출 제어 (최대 25%) |
| 19 | **온라인 보정** | 누적 응답으로 IRT 파라미터 자동 업데이트 |
| 20 | **관리자 API** | 서버 통계, 풀 건강도, 보정, 정리 |

---

## 3. 작동 원리

### 전체 데이터 플로우

```
1. 사용자 프로필 입력
   grade + self_assess + exam_experience + question_type
                    │
                    ▼
2. 초기 θ 추정
   GRADE_THETA[grade] + SELF_ASSESS_ADJUST[level] + EXAM_ADJUST[exam]
   예: 중2 + 중급 + 없음 → θ₀ = 0.0 + 0.0 + 0.0 = 0.0
                    │
                    ▼
3. CAT 세션 생성
   ├── 인메모리 CATSession (θ=0.0, SE=1.5)
   ├── DB에 User + TestSession 생성
   └── 9,183개 문항 풀에서 Type 1 파라미터 로드
                    │
                    ▼
4. 적응형 문항 루프 (15~40회 반복)
   ┌────────────────────────────────────────────────────┐
   │                                                    │
   │  4a. 문항 선택                                     │
   │      ├── 이미 출제된 문항 제외                       │
   │      ├── 콘텐츠 제약 적용                           │
   │      │   ├── 같은 주제 최대 3문항                    │
   │      │   ├── 외래어 최대 2문항                       │
   │      │   └── 문항 유형 진행도 필터                    │
   │      ├── Sympson-Hetter 노출 통제                   │
   │      ├── 후보별 피셔 정보량 I(θ) 계산                │
   │      └── 상위 5개 중 랜덤 선택                       │
   │                    │                               │
   │  4b. 유형 결정 (혼합 모드)                           │
   │      ├── preferred_question_types(items_completed)  │
   │      ├── 단어 데이터 가용성 필터                      │
   │      ├── 최소 출제 유형 우선                          │
   │      └── b += QUESTION_TYPE_B_MODIFIER[type]        │
   │                    │                               │
   │  4c. 문항 콘텐츠 생성                               │
   │      ├── DistractorEngine.generate_item()           │
   │      ├── 4가지 전략(A/B/C/D) 중 유형에 맞는 것 적용    │
   │      ├── 정답 + 오답 3개 셔플                        │
   │      └── 이중 언어 해설 생성                          │
   │                    │                               │
   │  4d. 사용자 응답                                    │
   │      ├── 선택지 클릭 또는 "모름"                      │
   │      └── 응답 시간(ms) 기록                          │
   │                    │                               │
   │  4e. θ 재추정 (EAP)                                │
   │      ├── 41점 구적점에서 사후확률 계산                  │
   │      ├── "모름"이면 guessing_c → 0                   │
   │      ├── θ_hat = 사후분포의 기댓값                    │
   │      └── SE = 사후분포의 표준편차                      │
   │                    │                               │
   │  4f. DB 저장                                       │
   │      Response 레코드: θ_before, θ_after,            │
   │      SE_before, SE_after, item 메타데이터             │
   │                    │                               │
   │  4g. 종료 판단                                      │
   │      ├── items >= 40? → 종료 (max_items)            │
   │      ├── items < 15? → 계속                         │
   │      ├── SE < 0.30? → 종료 (se_threshold)           │
   │      └── 최근 5회 θ 변화 < 0.05? → 종료 (convergence)│
   │                                                    │
   └────────────────────────────────────────────────────┘
                    │
                    ▼
5. 진단 리포트 생성
   ├── θ → CEFR 레벨 + 확률 분포
   ├── θ → 한국 교육과정 수준
   ├── θ → 추정 어휘 크기 (ΣP across 9,183 items)
   ├── Oxford 3000 커버리지
   ├── 주제별 강약점 (정답률 ≥70% 강점, <50% 약점)
   ├── 5차원 점수 (유형→차원 매핑)
   └── 신뢰도 = 1 - SE²
                    │
                    ▼
6. 결과 표시 (4탭)
   ├── 종합: CEFR 카드 + 레이더 차트 + Oxford 커버리지
   ├── 분석: 차원별 바 차트 + 주제 강약점 + 측정 상세
   ├── 학습: 4주 로드맵 + 차원별 연습 (지연 로딩)
   └── 매트릭스: 100단어 × 5상태 그리드 (지연 로딩)
```

### 핵심 수학 공식 요약

| 용도 | 공식 |
|------|------|
| 정답 확률 (2PL) | `P = 1 / (1 + exp(-a(θ-b)))` |
| 정답 확률 (3PL) | `P = c + (1-c) / (1 + exp(-a(θ-b)))` |
| 피셔 정보량 (2PL) | `I = a² × P × (1-P)` |
| 피셔 정보량 (3PL) | `I = a² × (1-P) × (P-c)² / ((1-c)² × P)` |
| EAP 추정 | `θ̂ = Σ(θᵢ × L(θᵢ) × π(θᵢ)) / Σ(L(θᵢ) × π(θᵢ))` |
| EAP 표준오차 | `SE = √(Σ((θᵢ-θ̂)² × L(θᵢ) × π(θᵢ)) / Σ(L(θᵢ) × π(θᵢ)))` |
| 신뢰도 | `reliability = 1 - SE²` |
| 어휘 크기 | `vocab_size = Σᵢ P(θ̂, aᵢ, bᵢ)` for all 9,183 items |

### 주요 설정값

| 설정 | 값 | 의미 |
|------|-----|------|
| `CAT_MIN_ITEMS` | 15 | 최소 문항 수 |
| `CAT_MAX_ITEMS` | 40 | 최대 문항 수 |
| `CAT_SE_THRESHOLD` | 0.30 | 정밀도 종료 기준 |
| `CAT_CONVERGENCE_WINDOW` | 5 | 수렴 판단 윈도우 |
| `CAT_CONVERGENCE_EPSILON` | 0.05 | 수렴 판단 기준 |
| `CAT_MAX_EXPOSURE_RATE` | 0.25 | 최대 문항 노출률 |
| `EAP_QUADRATURE_POINTS` | 41 | EAP 구적점 수 |
| `THETA_RANGE` | (-3.0, +3.0) | θ 범위 |
| `A_RANGE` | (0.4, 2.5) | 변별도 범위 |

---

## 4. 사용 방법

### 접속

- **URL**: https://vocab-cat-test.vercel.app
- **지원 기기**: PC, 태블릿, 모바일 (반응형)
- **지원 언어**: 한국어 / English (우측 상단 토글)

### 1단계: 프로필 입력

1. **닉네임**: 선택 사항 (미입력 시 "익명")
2. **학년**: 초3-4 ~ 성인 (10단계)
3. **자기평가**: 초급 / 중급 / 고급
4. **시험 경험**: 없음 / 내신 / 수능 / TOEIC / TOEFL
5. **문항 유형**: 혼합(추천) / 개별 유형 1~6
6. **[테스트 시작]** 클릭

### 2단계: 테스트 진행

- 화면에 영어 단어와 선택지 4개가 표시됨
- 정답이라고 생각하는 선택지를 클릭
- 정말 모르면 하단의 **[모름]** 버튼 클릭
- 답 선택 후 정답/오답 피드백 + 해설 표시
- **[다음 문항]** 클릭으로 진행
- 상단 진행 바에서 현재 진행도 확인 가능
- 15~40문항 후 자동 종료

### 3단계: 결과 확인

**종합 탭**: CEFR 레벨, 추정 어휘 수, 정답률, 신뢰도, 5차원 레이더 차트

**분석 탭**: 차원별 점수, 주제별 강약점, θ/SE/종료사유 등 측정 상세, 이전 테스트 기록

**학습 탭**: 약점 차원별 맞춤 연습, 4주 학습 로드맵

**매트릭스 탭**: 100개 대표 단어의 지식 상태 시각화

### API 직접 호출 (개발자용)

```bash
# 테스트 시작
curl -X POST https://vocab-cat-api-440067489993.us-central1.run.app/api/v1/test/start \
  -H "Content-Type: application/json" \
  -d '{"nickname":"test","grade":"중2","self_assess":"intermediate","exam_experience":"none","question_type":0}'

# 응답 제출
curl -X POST .../api/v1/test/{session_id}/respond \
  -H "Content-Type: application/json" \
  -d '{"item_id":123,"is_correct":true,"is_dont_know":false,"response_time_ms":3500}'

# 결과 조회
curl .../api/v1/test/{session_id}/results

# 학습 계획
curl .../api/v1/learn/{session_id}/plan

# 어휘 매트릭스
curl .../api/v1/learn/{session_id}/matrix

# 관리자 통계
curl .../api/v1/admin/stats
```

---

## 5. 장점

### 심리측정학적 장점

| 장점 | 설명 |
|------|------|
| **효율성** | 15~40문항으로 100문항 고정 시험과 동등한 정밀도 달성 |
| **정밀도** | SE < 0.30 (신뢰도 > 91%) 달성 시 조기 종료 |
| **적응성** | 모든 학습자에게 최적화된 난이도의 문항 제시 |
| **공정성** | 너무 쉬거나 어려운 문항으로 시간 낭비하지 않음 |
| **검증됨** | 10,000명 시뮬레이션 결과: RMSE 0.327, 상관 0.975, 65.8% 조기종료 |

### 콘텐츠 장점

| 장점 | 설명 |
|------|------|
| **대규모 문항 풀** | 9,183개 단어 × 6유형 = 이론적 55,000+ 문항 |
| **다차원 분석** | 의미·관계·문맥·형태·화용 5차원 프로필 |
| **풍부한 메타데이터** | 58개 컬럼의 단어별 정보 활용 |
| **그래프 기반 오답** | 의미적 형제 관계를 이용한 고품질 오답 |
| **다중 국제 기준** | CEFR, 한국 교육과정, GSE, Lexile 동시 매핑 |

### 기술적 장점

| 장점 | 설명 |
|------|------|
| **콜드 스타트 해결** | 메타데이터 기반 파라미터 초기화로 사전 보정 데이터 없이 운영 가능 |
| **자가 개선** | 베이지안 온라인 보정으로 사용할수록 정확해짐 |
| **확장 가능** | 2PL → 3PL 자동 전환 경로 내장 (5,000세션 후) |
| **외래어 인식** | 한국어 화자 특화 — 투명 외래어 자동 감지 및 처리 |
| **이중 언어** | 전체 UI와 해설이 한국어/영어 동시 지원 |
| **노출 통제** | Sympson-Hetter 알고리즘으로 문항 유출 위험 최소화 |

### 사용자 경험 장점

| 장점 | 설명 |
|------|------|
| **짧은 소요 시간** | 보통 10~15분 내 완료 |
| **즉시 결과** | 시험 종료 즉시 상세 분석 리포트 |
| **실행 가능한 피드백** | "결과" → "왜" → "어떻게 개선" 까지 일관된 흐름 |
| **재시험 용이** | 적응형이라 매번 다른 문항 세트 |

---

## 6. 한계점

### 심리측정학적 한계

| 한계 | 상세 | 영향도 |
|------|------|--------|
| **사전 보정 부재** | IRT 파라미터가 메타데이터 추정치이지 실제 응답 데이터 기반이 아님 | 높음 |
| **단일 차원 모델** | 5차원 분석은 사후 집계일 뿐, CAT 선택은 단일 θ 기반 | 중간 |
| **3PL 미활성** | 추측 파라미터(c)가 아직 0.0 — 찍기 효과 미보정 | 중간 |
| **DIF 미분석** | 성별/지역별 차별적 문항 기능(Differential Item Functioning) 분석 없음 | 낮음 |
| **표본 의존** | 베이지안 보정이 충분한 응답(20~500건) 축적 전까지는 초기 추정치에 의존 | 중간 |

### 데이터 한계

| 한계 | 상세 | 영향도 |
|------|------|--------|
| **반의어 채움률 43%** | 반의어가 자연적으로 없는 단어도 있지만, Type 4 문항 풀이 제한됨 | 중간 |
| **LLM 생성 데이터** | 예문, 정의, 교수법 등이 Gemini API 생성물 — 간혹 부정확 가능 | 중간 |
| **그래프 일부 커버리지** | vocabulary_graph.json이 전체 9,183개 중 5,124개만 노드로 포함 | 낮음 |
| **정적 토픽 매핑** | 3,300개 원시 주제의 27개 카테고리 매핑이 키워드 기반 — 모호한 경우 존재 | 낮음 |

### 기술적 한계

| 한계 | 상세 | 영향도 |
|------|------|--------|
| **인메모리 세션** | 서버 재시작 시 진행 중 세션 소실 | 높음 |
| **SQLite** | 동시 쓰기 제한 — 고트래픽 환경에서 병목 | 중간 |
| **단일 인스턴스** | Cloud Run 인스턴스 간 세션 공유 불가 | 중간 |
| **콜드 스타트** | 서버 기동 시 9,183개 단어 + 그래프 로딩에 수 초 소요 | 낮음 |
| **응답 시간 미활용** | response_time_ms를 수집하지만 IRT 모델에 반영하지 않음 | 낮음 |

### UX 한계

| 한계 | 상세 | 영향도 |
|------|------|--------|
| **Form/Pragmatic 차원 비활성** | 5차원 중 2개(형태, 화용)에 매핑되는 문항 유형이 아직 없음 | 중간 |
| **학습 계획 정적** | 추천 학습 계획이 생성 시점의 스냅샷 — 진행 추적 없음 | 중간 |
| **오프라인 미지원** | 인터넷 연결 필수 | 낮음 |
| **접근성** | 스크린 리더, 키보드 네비게이션 등 웹 접근성 미검증 | 낮음 |

---

## 7. 추가 개선 가능성

### 단기 개선 (1~2주)

| # | 개선 | 설명 | 난이도 |
|---|------|------|--------|
| 1 | **Redis 세션 저장** | 인메모리 dict → Redis로 전환, 서버 재시작 안전 + 다중 인스턴스 공유 | 중간 |
| 2 | **PostgreSQL 마이그레이션** | SQLite → PostgreSQL로 동시성 문제 해결 | 중간 |
| 3 | **응답 시간 활용** | response_time_ms를 로그정규분포 기반 가중치로 θ 추정에 반영 | 중간 |
| 4 | **3PL 활성화 조건 완화** | 5,000세션 대신 조건부 조기 활성화 (고빈도 문항부터) | 낮음 |
| 5 | **PWA 변환** | 오프라인 지원 + 홈 화면 추가 가능한 Progressive Web App | 낮음 |

### 중기 개선 (1~2개월)

| # | 개선 | 설명 | 난이도 |
|---|------|------|--------|
| 6 | **Type 7: 단어 형태 변환** | run→running, happy→happiness (Form 차원 활성화) | 중간 |
| 7 | **Type 8: 격식/비격식 판단** | "commence" vs. "start" 레지스터 구분 (Pragmatic 차원 활성화) | 중간 |
| 8 | **다차원 IRT (MIRT)** | 5차원 동시 추정 — θ 벡터 기반 문항 선택 | 높음 |
| 9 | **동적 학습 추적** | 학습 계획 진행 추적 + 적응형 학습 경로 | 높음 |
| 10 | **음성 문항** | TTS로 발음 듣기 문항 유형 추가 | 중간 |
| 11 | **DIF 분석** | 성별/학년별 차별적 문항 기능 탐지 및 편향 문항 제거 | 중간 |
| 12 | **A/B 테스트 프레임워크** | 파라미터 변경의 측정 정확도 영향을 실험적으로 검증 | 중간 |

### 장기 개선 (3개월+)

| # | 개선 | 설명 | 난이도 |
|---|------|------|--------|
| 13 | **Neo4j 마이그레이션** | 그래프 DB를 Neo4j로 전환하여 실시간 의미 쿼리 성능 향상 | 높음 |
| 14 | **LLM 동적 문항 생성** | 미리 만들어둔 문항이 아닌 실시간 GPT/Gemini 기반 문항 생성 | 높음 |
| 15 | **교사 대시보드** | 학급 단위 결과 분석, 학생 비교, 약점 집계 | 높음 |
| 16 | **학습자 모델링** | 장기간 학습 이력 기반 개인화 난이도 프로필 | 높음 |
| 17 | **다국어 확장** | 일본어, 중국어 화자 대상 어휘 진단 (CEFR-J 데이터 활용) | 높음 |
| 18 | **모바일 네이티브 앱** | React Native / Flutter로 네이티브 앱 전환 | 높음 |
| 19 | **간격 반복(SRS) 통합** | Anki/SuperMemo 스타일 복습 주기 + CAT 재평가 사이클 | 높음 |
| 20 | **표준화 인증** | 한국교육과정평가원 등 공인 기관과 협력하여 검사 도구 표준화 | 매우 높음 |

### 개선 우선순위 매트릭스

```
영향도 높음 ┤
            │  ⑧ MIRT          ⑮ 교사 대시보드
            │
            │  ① Redis    ⑥⑦ Form/Pragmatic 유형
            │  ② PostgreSQL
            │
            │  ③ 응답시간    ⑨ 동적학습    ⑫ A/B 테스트
            │
            │  ⑤ PWA      ⑪ DIF 분석
영향도 낮음 ┤  ④ 3PL 조기활성화
            └────────────────────────────────────
            낮은 난이도                     높은 난이도
```

---

## 부록: 전체 API 엔드포인트 목록

| Method | Path | 용도 |
|--------|------|------|
| GET | `/` | 서비스 정보 (버전, 로딩 상태) |
| GET | `/health` | 헬스 체크 |
| POST | `/api/v1/test/start` | 적응형 테스트 시작 |
| POST | `/api/v1/test/{session_id}/respond` | 응답 제출 → 다음 문항 또는 결과 |
| GET | `/api/v1/test/{session_id}/results` | 완료된 테스트 결과 조회 |
| GET | `/api/v1/user/{user_id}/history` | 사용자 테스트 히스토리 |
| POST | `/api/v1/admin/recalibrate` | IRT 파라미터 재보정 |
| GET | `/api/v1/admin/stats` | 서버 통계 |
| POST | `/api/v1/admin/cleanup` | 만료 세션 정리 |
| GET | `/api/v1/admin/exposure` | 문항 노출 분석 리포트 |
| GET | `/api/v1/admin/exposure/expansion` | 풀 확장 필요 분석 |
| GET | `/api/v1/learn/{session_id}/plan` | 맞춤 학습 계획 |
| GET | `/api/v1/learn/{session_id}/matrix` | 어휘 매트릭스 데이터 |

---

## 부록: 배포 정보

| 구성요소 | 서비스 | URL |
|----------|--------|-----|
| 프론트엔드 | Vercel | https://vocab-cat-test.vercel.app |
| 백엔드 API | Google Cloud Run | https://vocab-cat-api-440067489993.us-central1.run.app |
| 그래프 시각화 | Vercel | https://vocab-graph-db.vercel.app |
| GCP 프로젝트 | vocab-cat-irt | us-central1 |

---

*이 문서는 2026-02-22 기준 vocabulary-db 프로젝트의 전체 개발 과정과 최종 앱 분석을 정리한 것입니다.*
